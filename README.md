# Toyceptron - Perceptron Multi-Couches

## ğŸ“ Description

ImplÃ©mentation **from scratch** d'un rÃ©seau de neurones multi-couches (perceptron) en **Python pur**, sans aucune bibliothÃ¨que externe (numpy, torch, sklearn, etc.).

L'objectif pÃ©dagogique est de **comprendre en profondeur** le fonctionnement interne d'un rÃ©seau de neurones en codant chaque composant Ã  la main : neurones, couches, forward pass, fonctions d'activation.

---

## âœ¨ FonctionnalitÃ©s

- âœ… Construction d'un neurone avec poids, biais et fonction d'activation
- âœ… CrÃ©ation de couches (layers) avec initialisation alÃ©atoire des poids
- âœ… Architecture rÃ©seau multi-couches personnalisable
- âœ… 4 fonctions d'activation : identitÃ©, Heaviside, sigmoÃ¯de, ReLU
- âœ… Forward pass complÃ¨te Ã  travers le rÃ©seau
- âœ… MÃ©thode `summary()` pour afficher l'architecture (optionnel)

---

## ğŸ—ï¸ Architecture du projet

Toyceptron/
â”œâ”€â”€ neuron.py # Classe Neuron (calcul forward d'un neurone)
â”œâ”€â”€ layer.py # Classe Layer (couche de neurones)
â”œâ”€â”€ network.py # Classe Network (rÃ©seau multi-couches)
â”œâ”€â”€ activations.py # Fonctions d'activation
â”œâ”€â”€ main.py # Script de dÃ©monstration
â””â”€â”€ README.md # Ce fichier


---

## ğŸš€ Utilisation

### Lancer le projet

```bash
python main.py
```
#Exemple basique
from network import Network
from activations import relu, sigmoid

# CrÃ©er un rÃ©seau : 2 inputs â†’ 3 hidden â†’ 1 output
net = Network(layer_sizes=, activations=[relu, sigmoid])[1]

# Forward pass
result = net.forward([1.0, 2.0])
print(f"Sortie : {result}")

ğŸ§  Concepts clÃ©s
Neurone artificiel
Un neurone effectue 3 opÃ©rations :

Produit scalaire : 
z
=
w
1
x
1
+
w
2
x
2
+
.
.
.
+
w
n
x
n
z=w 
1
 x 
1
 +w 
2
 x 
2
 +...+w 
n
 x 
n
 

Ajout du biais : 
z
=
z
+
b
z=z+b

Activation : 
sortie
=
f
(
z
)
sortie=f(z)

Couche (Layer)
Collection de neurones recevant les mÃªmes inputs et produisant une liste de sorties.

Exemple : une couche de 3 neurones avec 2 inputs produit 3 sorties.

RÃ©seau (Network)
Empilement de couches oÃ¹ les sorties d'une couche deviennent les inputs de la suivante.

SchÃ©ma :
