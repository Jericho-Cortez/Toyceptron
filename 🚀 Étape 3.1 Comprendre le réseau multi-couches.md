<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# Sprint Toyceptron - JOUR 3 dÃ©marrÃ©

Ã‰tape 3.1 : Comprendre le rÃ©seau multi-couches
Go ! ğŸš€

Parfait ! ğŸš€ **Tu attaques le cÅ“ur du projet** : le rÃ©seau de neurones multi-couches. C'est lÃ  que tout se connecte.

***

## ğŸ§  Ã‰tape 3.1 : Comprendre le rÃ©seau multi-couches (30 min)

### Le concept fondamental

Un rÃ©seau multi-couches, c'est **une chaÃ®ne de Layer** oÃ¹ :

- La **sortie** d'une couche devient l'**entrÃ©e** de la suivante[^1]
- Chaque couche transforme progressivement les donnÃ©es
- La derniÃ¨re couche produit la prÃ©diction finale


### SchÃ©ma mental (forward pass)

```
Input Layer     â†’     Hidden Layer    â†’    Output Layer
[x1, x2, x3]    â†’    [h1, h2, h3, h4] â†’       [y1]
   (3 inputs)         (4 neurones)          (1 sortie)
```

**Le flux** :

1. Tu donnes `[x1, x2, x3]` au rÃ©seau
2. `Layer1` calcule `[h1, h2, h3, h4]` via ses 4 neurones
3. `Layer2` reÃ§oit `[h1, h2, h3, h4]` et calcule `[y1]`

***

## ğŸ¯ Visualisation sur TensorFlow Playground

**Action immÃ©diate** : Va sur https://playground.tensorflow.org[^1]

**Observe prÃ©cisÃ©ment** :

1. **Clique sur Play** : regarde les donnÃ©es circuler de gauche Ã  droite
2. **Les colonnes de cercles** = les **layers** (couches)
3. **Les lignes colorÃ©es** = les **poids** (bleu = nÃ©gatif, orange = positif)
4. **Chaque cercle** = un **neurone** avec son activation

**ExpÃ©rimente** :

- Change le nombre de couches cachÃ©es (ajoute/supprime des colonnes)
- Modifie le nombre de neurones par couche
- Change les fonctions d'activation (ReLU, Sigmoid, etc.)
- Observe comment le rÃ©seau apprend Ã  sÃ©parer les donnÃ©es

***

## ğŸ”— Lien avec ton code Python

### Ce que tu as dÃ©jÃ  codÃ©

âœ… **Neuron** : calcule `f(wÂ·x + b)` â†’ **UN cercle** sur le playground
âœ… **Layer** : groupe de neurones â†’ **UNE colonne** de cercles
âŒ **Network** : enchaÃ®nement de layers â†’ **TOUT le playground**

### Architecture attendue pour `network.py`

```python
from layer import Layer

class Network:
    def __init__(self, layer_sizes, activations):
        """
        layer_sizes: [3, 4, 1] = 3 inputs, 4 hidden, 1 output
        activations: [relu, sigmoid] = relu pour hidden, sigmoid pour output
        """
        self.layers = []
        # CrÃ©er chaque couche en cascade
        pass
    
    def forward(self, inputs):
        """
        Fait circuler les donnÃ©es Ã  travers toutes les couches
        """
        pass
```


***

## ğŸ”¢ Exemple numÃ©rique concret

**Configuration** :

- Input : `[1.0, 2.0]` (2 valeurs)
- Architecture : `[2, 3, 1]` = 2 inputs â†’ 3 hidden â†’ 1 output
- Activations : `[relu, sigmoid]`

**DÃ©roulÃ©** :

1. **Layer 1** (3 neurones, 2 inputs chacun) :
    - Neuron 1 : calcule `relu(1*w1 + 2*w2 + b1)` â†’ ex: `0.8`
    - Neuron 2 : calcule `relu(1*w3 + 2*w4 + b2)` â†’ ex: `0.0`
    - Neuron 3 : calcule `relu(1*w5 + 2*w6 + b3)` â†’ ex: `1.2`
    - **Sortie Layer 1** : `[0.8, 0.0, 1.2]`
2. **Layer 2** (1 neurone, 3 inputs) :
    - Neuron 1 : calcule `sigmoid(0.8*w7 + 0.0*w8 + 1.2*w9 + b4)` â†’ ex: `0.73`
    - **Sortie finale** : `[0.73]`

***

## ğŸ“ MathÃ©matiques derriÃ¨re le multi-couches

Pour chaque layer $l$ :

$$
\text{output}^{(l)} = f^{(l)}(\mathbf{W}^{(l)} \cdot \text{input}^{(l)} + \mathbf{b}^{(l)})
$$

Puis :

$$
\text{input}^{(l+1)} = \text{output}^{(l)}
$$

**En Python** :

```python
current = inputs
for layer in self.layers:
    current = layer.forward(current)
return current
```


***

## âœ… Validation de comprÃ©hension

**Tu dois pouvoir rÃ©pondre** :

1. Combien de layers dans un rÃ©seau `[5, 10, 3]` ? â†’ **2 layers** (une hidden, une output)
2. Si Layer1 a 4 neurones, combien de valeurs en sortie ? â†’ **4 valeurs**
3. Si Layer1 sort `[a, b, c]`, combien d'inputs pour chaque neurone de Layer2 ? â†’ **3 inputs**

***

## ğŸš€ Prochaine Ã©tape

Tu es maintenant prÃªt pour **l'Ã©tape 3.2 : Coder network.py** !

Tu veux que je te guide pour :

- Construire le `__init__()` avec la boucle de crÃ©ation des layers ?
- ImplÃ©menter le `forward()` qui enchaÃ®ne les couches ?
- Les deux d'un coup ? ğŸ’ª

<div align="center">â‚</div>

[^1]: ROADMAP-TOYCEPTRON-Mode-Sprint-3-4-jours.md

